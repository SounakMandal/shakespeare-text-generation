{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3cfb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f328e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file name to train on : shakespeare_sonnets\n",
      "Total character count :  94275\n"
     ]
    }
   ],
   "source": [
    "filename = input('Enter file name to train on : ')\n",
    "with open(filename+\".txt\") as f:\n",
    "    shakespeare_text = f.read()\n",
    "print(\"Total character count : \", len(shakespeare_text))\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([shakespeare_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100e57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1624468336', '1624523012', '1624534639', '1624603344']\n",
      "Enter position of model : 3\n",
      "Loading path :  .\\checkpoints_shakespeare_sonnets\\1624603344\\1624692026.h5\n"
     ]
    }
   ],
   "source": [
    "checkpoints_filepath = os.path.join(os.curdir, f\"checkpoints_{filename}\")\n",
    "directory = os.listdir(checkpoints_filepath)\n",
    "print(directory)\n",
    "\n",
    "base_model = directory[int(input('Enter position of model : '))]\n",
    "root_filepath = os.path.join(os.curdir, f\"checkpoints_{filename}\\\\{base_model}\")\n",
    "file_name = os.listdir(root_filepath)[-1]\n",
    "load_filepath = f\"{root_filepath}\\\\{file_name}\"\n",
    "print(\"Loading path : \", load_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb1333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 512)         847872    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 256)         591360    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 128)         148224    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, None, 64)          37248     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 38)          2470      \n",
      "=================================================================\n",
      "Total params: 1,627,174\n",
      "Trainable params: 1,627,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(load_filepath)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5260f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts))-1\n",
    "    return tf.one_hot(X, len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d28e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819f58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=100, temperature=1):\n",
    "    print(text, end=\"\")\n",
    "    for _ in range(n_chars):\n",
    "        next_ch = next_char(text, temperature)\n",
    "        print(next_ch, end=\"\")\n",
    "        text += next_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f778d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some intial text as context : Love\n",
      "\n",
      "Love's breath,\n",
      "that in the east thou belied, but perjured i,\n",
      "to say the reven's canst not born of less,\n"
     ]
    }
   ],
   "source": [
    "input_text = input('Enter some intial text as context : ')\n",
    "print()\n",
    "complete_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1adf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
